{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "mount_file_id": "18RMzd-ZyWCTm3X-rgo0lsZoye3p-nSqD",
      "authorship_tag": "ABX9TyPzlVSk3nFN4Ma70H6VzgPi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ron-Wu/Machine-learning-0602/blob/main/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PES8Nn576baa"
      },
      "source": [
        "\"\"\"\n",
        "建議可將圖片集生成壓縮檔再上傳google drive，\n",
        "之後再colab再使用 zipfile 功能來解壓縮，\n",
        "生成在colab的虛擬電腦中 \n",
        "\"\"\"\n",
        "import zipfile\n",
        "fn = \"/content/drive/MyDrive/additional/train.zip\"\n",
        "zf = zipfile.ZipFile(fn)\n",
        "zf.extractall()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdTPm_jAcxee"
      },
      "source": [
        "import glob\n",
        "fns = glob.glob(\"train/*\")\n",
        "print(len(fns))\n",
        "fns[0]\n",
        "\n",
        "from PIL import Image\n",
        "img = Image.open(fns[0])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "print(img.size) # 也可以轉成使用np.array 來看 .shape\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7XadvwpfKaT"
      },
      "source": [
        "\"\"\"\n",
        "因為每張圖片太大，如果直接讀圖RAM會炸掉，\n",
        "所以先把資料轉成序列\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "dogf = glob.glob(\"train/dog.*\")\n",
        "catf = glob.glob(\"train/cat.*\")\n",
        "data = pd.DataFrame({\n",
        "    \"path\":dogf+catf,\n",
        "    \"target\":[0] * len(dogf) + [1] * len(catf) # 做出 12500 個 0 的list和 12500 個 1 的list\n",
        "})\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze8SrZVzgqDX"
      },
      "source": [
        "\"\"\"\n",
        "%tensorflow_version 1.x # 如果有需要從tensorflow 1 的keras函數時可以這樣載入\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "vgg = VGG16(include_top=False,input_shape=(224, 224, 3))\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "# 如果用model一定要將tensor一層傳一層才可以串接在一起\n",
        "t1 = GlobalAveragePooling2D()(vgg.output)\n",
        "out = Dense(2, activation=\"softmax\")(t1)\n",
        "model = Model(inputs=vgg.input, outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv5rd4Roj2OL"
      },
      "source": [
        "# 如果用sequential則不一定要將tensor一層傳一層才可以串接在一起\n",
        "\n",
        "vgg = VGG16(include_top=False,input_shape=(224, 224, 3))\n",
        "# trainable一定要在compile之前\n",
        "for l in vgg.layers:\n",
        "  l.trainable = False\n",
        "layers=[\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(vgg.layers + layers)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DnUsz-Il7s9"
      },
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss = SparseCategoricalCrossentropy,\n",
        "               optimizer = Adam(),\n",
        "               metrics = [\"accuracy\"])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOb7UwfFnrzf"
      },
      "source": [
        "import numpy as np\n",
        "test = np.random.randint(0, 255, size=(3, 32, 32, 3)) # low=0, high=255\n",
        "# np.array[第一個軸我要哪幾個, 第二個軸我要哪幾個....]\n",
        "print(test.shape)\n",
        "print(test[0:2].shape)\n",
        "print(test[0:2,0:28,0:28,0:2].shape)\n",
        "print(test[:,:,:,0:2].shape)\n",
        "print(test[...,0:2].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXhrW7RY00LT"
      },
      "source": [
        "\"\"\"\n",
        "一張照片如何做處理\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "# 圖片如何處理: 不是除255.0, 請always使用你偷來的模型同樣處理方式\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\"\"\"\n",
        "Image.open(fns[0]) = 先開啟第一張圖片，\n",
        "convert(\"RGB\") = 把類別轉成RGB格式，\n",
        "resize((224, 224)) = 調整圖片大小以符合VGG16的模型，resize內必須是個tuple形式\n",
        "\"\"\"\n",
        "img = Image.open(fns[0]).convert(\"RGB\").resize((224, 224))\n",
        "\n",
        "# 將圖片轉成np.array\n",
        "img_np = np.array(img)\n",
        "# 將其套用到被遷移的模型預處理的preprocess_input\n",
        "preprocess_input(img_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0roWOML028x"
      },
      "source": [
        "\"\"\"\n",
        "一堆照片如何做處理，設計一個函式，套用進去\n",
        "\"\"\"\n",
        "# 我們無法使用fit, 1. fit_generator 2.train_on_batch/test_on_batch\n",
        "# random.randint(0, 2(inclusive)): 0,1,2 是包含2的\n",
        "# np.random,randint(0, 3(exclusive)): 0,1,2 沒有包含3\n",
        "def get_data(x, y, batch=20):\n",
        "    idx = np.random.randint(0, len(x), size=batch)\n",
        "    xidx, yidx = x[idx], y[idx]\n",
        "    img_ori, img_pre, ans = [], [], []\n",
        "    for xi, yi in zip(xidx, yidx):\n",
        "        img = Image.open(xi).convert(\"RGB\").resize((224, 224))\n",
        "        img_np = np.array(img)\n",
        "        img_p = preprocess_input(img_np)\n",
        "        img_ori.append(img_np)\n",
        "        img_pre.append(img_p)\n",
        "        ans.append(yi)\n",
        "    return np.array(img_ori), np.array(img_pre), np.array(ans)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ChByx21FNo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x, y = np.array(data[\"path\"]), np.array(data[\"target\"])\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "img_ori, img_pre, ans = get_data(x_train, y_train)\n",
        "print(img_ori.shape)\n",
        "print(img_pre.shape)\n",
        "print(ans.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSuewt3m6X0Z"
      },
      "source": [
        "for i in range(100):\n",
        "  print(\"-\" * 15, i, \"-\" * 15)\n",
        "  img_ori, img_p, ans = get_data(x_train, y_train)\n",
        "  # result = model.train_on_batch(img_pre, ans)\n",
        "  result = model.train_on_batch(img_p, ans)\n",
        "\n",
        "  print(\"train:\", result)\n",
        "  img_ori, img_p, ans = get_data(x_test, y_test)\n",
        "  result = model.test_on_batch(img_p, ans)\n",
        "  print(\"validate:\", result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jjmA1x3PJ1k"
      },
      "source": [
        "# 1. 發覺loss跳動幅度太高\n",
        "# 2. 發覺預測機率1.0 * e+0\n",
        "# 沒有把輸入調整到合理範圍(norm)\n",
        "img_ori, img_p, ans = get_data(x_test, y_test, batch=200)\n",
        "pre = model.predict(img_p)\n",
        "# Model沒有predict_classes可以用, 以後好像也要移除predict_classes\n",
        "classes = pre.argmax(axis=1)\n",
        "model.evaluate(img_p, ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siJd2XSVPKyz"
      },
      "source": [
        "import numpy as np\n",
        "names = [\"dog\", \"cat\"]\n",
        "idx = np.nonzero(classes != ans)[0]\n",
        "# np.nonzero([[0, 2, 0], [0, 0, 3]])\n",
        "false_pre = classes[idx]\n",
        "false_label = ans[idx] \n",
        "false_img = img_ori[idx]\n",
        "\n",
        "plt.figure(figsize=(14, 42))\n",
        "width = 10\n",
        "height = len(idx) // width + 1\n",
        "for i in range(len(false_img)):\n",
        "    plt.subplot(height, width, i+1)\n",
        "    title = \"[P]:{}\\n[O]:{}\".format(names[false_pre[i]], names[false_label[i]])\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(false_img[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U5_HVz8PTEM"
      },
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "url = input(\"輸入網址:\")\n",
        "response = requests.get(url, verify=False, stream=True)\n",
        "img = Image.open(response.raw)\n",
        "img = img.resize((224, 224)).convert(\"RGB\")\n",
        "img_np = np.array(img).reshape(1, 224, 224, 3)\n",
        "img_norm = preprocess_input(img_np)\n",
        "pre = model.predict(img_norm)[0]\n",
        "for n, p in zip(names, pre):\n",
        "    print(n, \"的機率:\", round(p, 3))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}